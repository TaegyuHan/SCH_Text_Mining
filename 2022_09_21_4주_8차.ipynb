{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SCH 빅데이터 공학과 3학년-2학기 텍스트 마이닝\n",
    "날짜 : 2022-09-21 수요일 15:00 4주 8차시\n",
    "교수 : 문지훈\n",
    "학생 : 한태규"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 정규 표현식\n",
    "- **텍스트 문자열의 패턴 파악 및 식별**을 위해 주로 사용하는 방법\n",
    "- 문자열이 **주어진 규칙에 일치 또는 불일치하는지를 판단** 할 수 있음\n",
    "- 특정 패턴을 지닌 문자열을 찾을 수 있어 텍스트 데이터 전처리 및 후처리에 사용되는 **크롤링 (Crawling)에 널리 활용** 되고 있음\n",
    "\n",
    "# 정규 표현식의 예시\n",
    "- 신문 기사 텍스트들을 수집 및 분석\n",
    "- 이메일 주요 문구가 분석에 방해 기본(중요함), 이메일 주소 (중요하지 않음)\n",
    "- **정교한 정제 작업이 필요**한 텍스트 데이터를 어떻게 처리할지에 관해 이해할 수 있다.\n",
    "- 텍스트 데이터의 **사전 처리를 수행**할 수 있다.\n",
    "- 대소문자 통일, 숫자, 문장부호, 특수문자 제거, 불용어 제거"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 정형화 과정 알아보기\n",
    "- **말뭉치 (Corpus)** : 텍스트 마이닝에 적용되는 대용량의 정형화된 텍스트 데이터 집합 > '정형화된'의 의미는 무엇일까?\n",
    "- **텍스트 정형화 과정** : 원(Raw) 텍스트 데이터를 정제하거나 사전 처리하는 작업 > 사전 처리를 어떻게 하느냐에 따라 결과가 다양함\n",
    "- 사전 처리 과정을 꼼꼼하고 신중하게 진행하여 최종 분석 결과를 더욱 빛내보자!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 대소문자 통일\n",
    "- 영어 대문자\n",
    "    - 첫 문장의 첫 단어\n",
    "    - 고유 명사\n",
    "    - 축약어\n",
    "    - 강조어\n",
    "- 파이썬 프로그래밍 언어 : 같은 철자라도 대문자와 소문자를 서로 다른 문자로 인식 > 대문자 > 소문자 또는 소문자 > 대문자로 통일"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'department of ai and big data'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Department of AI and Big Data\"\n",
    "s.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'DEPARTMENT OF AI AND BIG DATA'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.upper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 숫자, 문장부호, 특수문자 제거\n",
    "\n",
    "## 숫자 제거의 중요성\n",
    "- 일반적으로 원(Raw) 데이터는 텍스트뿐만 아니라 **숫자, 문장부호, 특수문자 등이 모두 포함**되어 있음 > 단어가 아니므로 분석할 때 필요 없는 경우가 대부분이나 분석가의 판단엥 따라 삭제 시 분석 결과가 왜곡된다고 생각되면 남겨둘 수도 있음\n",
    "- 각기 서로 다른 문서들에서 사용된 숫자들은 **크게 의미를 부여하기가 쉽지 않으며 때로는 혼란을 야기함**\n",
    "- 가격 **100% 상승**은 **2배 상승**으로 표현할 수 있음\n",
    "- 숫자는 각각 **100**과 **2**가 추출되므로 분석하기가 쉽지 않음"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'작년 나의 연봉은 만원 이었다.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숫자 제거 예시\n",
    "import re\n",
    "\n",
    "p = re.compile(\"[0-9]+\")\n",
    "p.sub(\"\", \"작년 나의 연봉은 4200만원 이었다.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "re.compile(r'[0-9]+', re.UNICODE)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 문장부호, 특수문자 제거의 중요성\n",
    "- 텍스트 데이터에는 많은 문장부호가 사용되며, 문장부호마다 고유한 문법적 혹은 의미론적인 기능이 있음\n",
    "    - 예 : 마침표, 콤마, 물음표, 느낌표등\n",
    "- 문장부호들은 각 문장에서는 특수한 역할을 수행할 수 있으나, **전체 말뭉치의 관점에서는 특정 의미를 부여하기가 어려움**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'내가세상에서가장사랑하는와이프'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\W+\")\n",
    "p.sub(\"\", \"내가 세상에서 가장 사랑하는 와이프♥♥\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'    ♥♥'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\w+\")\n",
    "p.sub(\"\", \"내가 세상에서 가장 사랑하는 와이프♥♥\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'내가_진심으로_바라는것은우리_학생들의_행복'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 문장부호 및 특수문자 제거\n",
    "p = re.compile(\"\\W+\")\n",
    "s = p.sub(\"\", \"내가_진심으로_바라는 것은 ~~ 우리_학생들의_행복\")\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'내가진심으로바라는것은우리학생들의행복'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"_\")\n",
    "p.sub(\"\", s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 불용어 제거\n",
    "\n",
    "- 텍스트 데이터에는 자주 사용되지만 특별한 의미를 부여하긱 힘든 단어들이 존재\n",
    "    - 예 : 'the', 'a', 'an'등과 같은 관사\n",
    "- 불용어 (Stopword) : 빈번하게 사용되나 구체적인 의미를 찾기 어려운 단어들\n",
    "- 언어 마다 **불용어 리스트를 라이브러리에서 제공** 해주는 경우가 많으며, 때로는 분석가가 개인적으로 불용어 리스트를 구성하고 추가 및 제거\n",
    "\n",
    "- NLTK : 파이썬에서 가장 많이 쓰는 텍스트 마이닝 패키지로 **언어별로 불용어 리스트를 제공**\n",
    "- 영어, 프랑스어, 독일어, 이탈리아어, 헝가리어, 필란드어, 덴마크어, 네덜란드어, 지원 및 각 언어에 필요한 불용어 리스트 제공\n",
    "- **한국어 지원하지 않음** > 개인적으로 작성하거나 다른 분석가, 연구자들이 작성한 리스트를 활용"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['효정', '미미', '유아', '승희', '유빈', '아린']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한국 불용어 제거\n",
    "words_Korean = [\"효정\", \"진이\", \"미미\", \"유아\", \"승희\", \"지호\", \"유빈\", \"아린\"]\n",
    "stopwords = [\"진이\", \"지호\"]\n",
    "[i for i in words_Korean if i not in stopwords]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chief', 'justice', 'roberts', ',', 'president', 'carter', ',', 'president', 'clinton', ',', 'president’, ‘bush’, ‘,’, ‘president’, ‘obama’, ‘,’, ‘fellow’, ‘americans', 'people', 'world', ',', 'thank', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "words_English = ['chief', 'justice', 'roberts', ',', 'president', 'carter', ',', 'president', 'clinton', ',',\n",
    "                 'president’, ‘bush’, ‘,’, ‘president’, ‘obama’, ‘,’, ‘fellow’, ‘americans', 'and', 'people', 'of',\n",
    "                 'the', 'world', ',', 'thank', 'you', '.']\n",
    "print([w for w in words_English if not w in stopwords.words(\"english\")])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}